- Introduction
    - What kind of problems can be solved with RL/MDP
    - Motivation: non-markovian/history dependent reward. Why this is difficult. Few possible approaches: state automata; LTL
    - Brief introduction to LTL and state automata
    - Present concrete problem formulation + contribution
- Related work

- Preliminaries
    - Tabular MDP
    - Notion of policy, value, Q-value, optimal policy, bellman equation, Value iteration/policy iteration (incl pseudo-code)
    - Q learning/DQL

- Problem formulation
    - Introduce RM, MDPRM, logically constrained problems etc.
    - Assumptions, learning protocol
    - RM known vs RM not known

- Different chapters
    - Algorithm + baseline
    - Experiment setup
    - Results

Note: when we did work to implement stuff.
